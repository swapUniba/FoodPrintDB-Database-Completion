{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RrQLC2uXMmPu",
        "Bby7rYQYk6RF",
        "jU7vvYgxlWHL",
        "EcnQp4PKI6Rq",
        "y-YuxfPYgBVa"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Imports"
      ],
      "metadata": {
        "id": "RrQLC2uXMmPu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRDrL9683B4O",
        "outputId": "2d35299c-bcd8-41c1-82c3-b716e676ae63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linking the dataset to data in the sql dataset\n",
        "\n",
        "This notebook is thinked as help to link every ingredient of the sql dataset by Amoruso & Fusillo to an entry of the Complete and Coherent Sueatable dataset (CSEL).\n",
        "\n",
        "An embedding based algorithm for compute semantic similarity between strings will be used to catch the most relatable ingredient for each entry of the sql dataset given as csv file.\n",
        "\n",
        "All the matches are given as suggestion, is necessary to manually check their reliability."
      ],
      "metadata": {
        "id": "Bby7rYQYk6RF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ingredient-name matching algorithm.\n",
        "\n",
        "Search for match between the ingredient name in the FoodPrintDB and the food item name in the CSEL Dataset"
      ],
      "metadata": {
        "id": "jU7vvYgxlWHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "hYmxoz_tmSnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "ingredients = pd.read_csv(\"/content/drive/MyDrive/Semantics In Intelligent Information Access/SuEatableLife/food_print_ingredients.csv\")\n",
        "sueatable = pd.read_csv(\"/content/drive/MyDrive/Semantics In Intelligent Information Access/SuEatableLife/_Finalized/cfp_wfp_ingredients.csv\",sep= ';')\n",
        "\n",
        "embedding_sue = model.encode(sueatable['Food commodity ITEM'])\n",
        "\n",
        "for _, ingredient_row in ingredients.iterrows():\n",
        "  embedding_ing = model.encode(ingredient_row['name'])\n",
        "  scores = []  \n",
        "  scores = util.pytorch_cos_sim(embedding_ing, embedding_sue).flatten()\n",
        "  sorted = scores.argsort()[-2:]\n",
        "  print(ingredient_row['name'])\n",
        "  for i in sorted:\n",
        "    max_score_idx = int(i)\n",
        "    max_score = float(scores[max_score_idx])\n",
        "    \n",
        "    print(sueatable['Food commodity ITEM'][max_score_idx])\n",
        "    print(max_score)\n",
        "    print(\"update ingredients set carbon_foot_print =\"+str(sueatable['final_co2'][max_score_idx]).replace(\",\", \".\")+\", water_foot_print = \"+str(sueatable['final_wfp'][max_score_idx]).replace(\",\", \".\")+\", carbon_foot_print_source\t= 'sueatable', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable', water_foot_print_weight =\t1000 where ingredient_id =\"+str(ingredient_row['ingredient_id'])+\";\")\n",
        "    print(\"insert into ingredients_name_alias values (\"+str(ingredient_row['ingredient_id'])+\",'\"+str(sueatable['Food commodity ITEM'][max_score_idx])+\"');\")\n",
        "    print('***************************************')\n",
        "  print('#######################################')"
      ],
      "metadata": {
        "id": "SIZ797fg4bqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ingredient-typology matching algorithm.\n",
        "\n",
        "Search for match between the ingredient name in the FoodPrintDB and the cfp/wf typology of the SEL Database.\n",
        "\n",
        "Could be useful applyu a filter on the FoodPrintDB csv in order to work only on prfeviosly missed ingredients (in the next section there is a working example of filtering on FoodPrintDB)."
      ],
      "metadata": {
        "id": "EcnQp4PKI6Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "ingredients = pd.read_csv(\"/content/drive/MyDrive/Semantics In Intelligent Information Access/SuEatableLife/food_print_ingredients.csv\")\n",
        "\n",
        "co2_typ = pd.read_csv(\"/content/drive/MyDrive/Semantics In Intelligent Information Access/SuEatableLife/co2_median_typology.csv\", sep= ';')\n",
        "wfp_typ = pd.read_csv(\"/content/drive/MyDrive/Semantics In Intelligent Information Access/SuEatableLife/wfp_median_typology.csv\", sep= ';')\n",
        "\n",
        "#remove from the \"Typology\" fields * and parentheses\n",
        "prt_regex = '\\((\\w*\\W*\\s*)*\\)' #remove parentheses and their content\n",
        "star_regex = '\\*' #remove *\n",
        "\n",
        "co2_typ['FOOD COMMODITY TYPOLOGY'] = co2_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace=prt_regex, value='', regex=True)\n",
        "co2_typ['FOOD COMMODITY TYPOLOGY'] = co2_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace=star_regex, value='', regex=True)\n",
        "\n",
        "wfp_typ['FOOD COMMODITY TYPOLOGY'] = wfp_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace=prt_regex, value='', regex=True)\n",
        "wfp_typ['FOOD COMMODITY TYPOLOGY'] = wfp_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace=star_regex, value='', regex=True)\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "embedding_co2_typ = model.encode(co2_typ['FOOD COMMODITY TYPOLOGY'], convert_to_tensor=True)\n",
        "embedding_wfp_typ = model.encode(wfp_typ['FOOD COMMODITY TYPOLOGY'], convert_to_tensor=True)\n",
        "\n",
        "\n",
        "for _, ingredient_row in ingredients.iterrows():\n",
        "  embedding_ing = model.encode(ingredient_row['name'], convert_to_tensor=True)\n",
        "\n",
        "  scores_co2_typ = []\n",
        "  scores_wfp_typ = []  \n",
        "  scores_co2_typ = util.pytorch_cos_sim(embedding_ing, embedding_co2_typ)  \n",
        "  scores_wfp_typ = util.pytorch_cos_sim(embedding_ing, embedding_wfp_typ)  \n",
        "  \n",
        "  #select the right co2 typology\n",
        "  co2_max_score_idx = int(np.argmax(scores_co2_typ))\n",
        "  co2_max_score = float(scores_co2_typ[0,co2_max_score_idx])\n",
        "  #select the right wfp typology\n",
        "  wfp_max_score_idx = int(np.argmax(scores_wfp_typ))\n",
        "  wfp_max_score = float(scores_wfp_typ[0,wfp_max_score_idx])\n",
        "\n",
        "  print(ingredient_row['name'])\n",
        "  print('****Guessing typologies for cfp and wfp****')\n",
        "  guessed_typology = co2_typ['FOOD COMMODITY TYPOLOGY'][co2_max_score_idx]\n",
        "  print(guessed_typology)\n",
        "  print(co2_max_score)\n",
        "  print(wfp_typ['FOOD COMMODITY TYPOLOGY'][wfp_max_score_idx])\n",
        "  print(wfp_max_score)\n",
        "  print(\"update ingredients set carbon_foot_print =\"+str(co2_typ['median'][co2_max_score_idx]).replace(\",\", \".\")+\", water_foot_print = \"+str(wfp_typ['median'][wfp_max_score_idx]).replace(\",\", \".\")+\", carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =\"+str(ingredient_row['ingredient_id'])+\";\")\n",
        "  print('#######################################')\n"
      ],
      "metadata": {
        "id": "VvxlXcduJDSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Place for finetune typology matching algorithm.\n",
        "\n",
        "Used to force match between specific igrdiendts and cfp/wfp typologies.\n",
        "\n",
        "Must be adapted to every specific circumstance."
      ],
      "metadata": {
        "id": "y-YuxfPYgBVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "ingredients = pd.read_csv(\"/content/drive/MyDrive/Semantics In Intelligent Information Access/SuEatableLife/food_print_ingredients.csv\")\n",
        "\n",
        "d={'name': \n",
        "[\"nuts, pine nuts, dried\",\n",
        "\"nuts, macadamia nuts, raw\",\n",
        "\"nuts, pecans\",\n",
        "\"kashi, steam meal, chicken fettuccine, frozen entree\",\n",
        "\"dill weed, fresh\",\n",
        "\"parsley, fresh\",\n",
        "\"terra dolce, organic chipotle dried chile peppers, upc: 700360007144\",\n",
        "\"spices, pepper, red or cayenne\",\n",
        "\"spices, pepper, black\",\n",
        "\"spices, basil, dried\",\n",
        "\"kale, raw\",\n",
        "\"chives, raw\",\n",
        "\"squash, winter, butternut, raw\",\n",
        "\"arugula, raw\"],\n",
        "'typology': \n",
        "[\"NUTS\",\n",
        "\"NUTS\",\n",
        "\"NUTS\",\n",
        "\"POULTRY BONE FREE MEAT\",\n",
        "\"SPICIES\",\n",
        "\"SPICIES\",\n",
        "\"SPICIES\",\n",
        "\"SPICIES\",\n",
        "\"SPICIES\",\n",
        "\"SPICIES\",\n",
        "\"VEGETABLES\",\n",
        "\"VEGETABLES\",\n",
        "\"VEGETABLES\",\n",
        "\"VEGETABLES\"]}\n",
        "\n",
        "to_be_fixed = pd.DataFrame(data=d)\n",
        "\n",
        "ingredients = pd.merge(ingredients, to_be_fixed, on='name', suffixes=('', '_new'))\n",
        "print(ingredients['typology'].unique())"
      ],
      "metadata": {
        "id": "b0kOOKdLRhAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070da5db-f63f-4a59-f042-687ca5136126"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NUTS' 'SPICIES' 'VEGETABLES' 'POULTRY BONE FREE MEAT']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "co2_typ = pd.read_csv(\"/content/drive/MyDrive/Semantics In Intelligent Information Access/SuEatableLife/co2_median_typology.csv\", sep= ';')\n",
        "wfp_typ = pd.read_csv(\"/content/drive/MyDrive/Semantics In Intelligent Information Access/SuEatableLife/wfp_median_typology.csv\", sep= ';')\n",
        "\n",
        "#remove from the \"Typology\" fields * and parentheses\n",
        "prt_regex = '\\((\\w*\\W*\\s*)*\\)' #remove parentheses and their content\n",
        "star_regex = '\\*' #remove *\n",
        "\n",
        "co2_typ['FOOD COMMODITY TYPOLOGY'] = co2_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace=prt_regex, value='', regex=True)\n",
        "co2_typ['FOOD COMMODITY TYPOLOGY'] = co2_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace='VEGETABLES OPENFIELD', value='VEGETABLES', regex=True)\n",
        "co2_typ['FOOD COMMODITY TYPOLOGY'] = co2_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace=star_regex, value='', regex=True)\n",
        "\n",
        "wfp_typ['FOOD COMMODITY TYPOLOGY'] = wfp_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace=prt_regex, value='', regex=True)\n",
        "wfp_typ['FOOD COMMODITY TYPOLOGY'] = wfp_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace='NUTS WITH SHELL', value='', regex=True)\n",
        "wfp_typ['FOOD COMMODITY TYPOLOGY'] = wfp_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace='NUTS SHELLED', value='NUTS', regex=True)\n",
        "wfp_typ['FOOD COMMODITY TYPOLOGY'] = wfp_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace='LEGUMES FRESH', value='LEGUMES', regex=True)\n",
        "wfp_typ['FOOD COMMODITY TYPOLOGY'] = wfp_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace='COCOA DERIVATES', value='CHOCOLATE', regex=True)\n",
        "wfp_typ['FOOD COMMODITY TYPOLOGY'] = wfp_typ['FOOD COMMODITY TYPOLOGY'].replace(to_replace=star_regex, value='', regex=True)\n",
        "\n",
        "###############################################################################\n",
        "embedding_co2_typ = model.encode(co2_typ['FOOD COMMODITY TYPOLOGY'], convert_to_tensor=True)\n",
        "embedding_wfp_typ = model.encode(wfp_typ['FOOD COMMODITY TYPOLOGY'], convert_to_tensor=True)\n",
        "\n",
        "for _, ingredient_row in ingredients.iterrows():\n",
        "  embedding_ing = model.encode(ingredient_row['typology'], convert_to_tensor=True)\n",
        "\n",
        "  scores_co2_typ = []\n",
        "  scores_wfp_typ = []  \n",
        "  scores_co2_typ = util.pytorch_cos_sim(embedding_ing, embedding_co2_typ)  \n",
        "  scores_wfp_typ = util.pytorch_cos_sim(embedding_ing, embedding_wfp_typ)  \n",
        "  \n",
        "  #select the right co2 typology\n",
        "  co2_max_score_idx = int(np.argmax(scores_co2_typ))\n",
        "  co2_max_score = float(scores_co2_typ[0,co2_max_score_idx])\n",
        "  #select the right wfp typology\n",
        "  wfp_max_score_idx = int(np.argmax(scores_wfp_typ))\n",
        "  wfp_max_score = float(scores_wfp_typ[0,wfp_max_score_idx])\n",
        "\n",
        "  print(ingredient_row['typology'])\n",
        "  alias_name = ingredient_row['name'].upper().replace(',','')\n",
        "\n",
        "  guessed_typology = co2_typ['FOOD COMMODITY TYPOLOGY'][co2_max_score_idx]\n",
        "  print(guessed_typology)\n",
        "  print(co2_max_score)\n",
        "  print(wfp_typ['FOOD COMMODITY TYPOLOGY'][wfp_max_score_idx])\n",
        "  print(wfp_max_score)\n",
        "  print(\"update ingredients set carbon_foot_print =\"+str(co2_typ['median'][co2_max_score_idx]).replace(\",\", \".\")+\", water_foot_print = \"+str(wfp_typ['median'][wfp_max_score_idx]).replace(\",\", \".\")+\", carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =\"+str(ingredient_row['ingredient_id'])+\";\")\n",
        "  print(\"insert into ingredients_name_alias values (\"+str(ingredient_row['ingredient_id'])+\",'\"+alias_name+\"');\")\n",
        "  print('#######################################')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fZ9UqMmPieUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3711799-abf0-40f0-bb05-664023a3bfb5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUTS\n",
            "NUTS\n",
            "1.0\n",
            "NUTS\n",
            "1.0\n",
            "update ingredients set carbon_foot_print =1.11, water_foot_print = 11264, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =42;\n",
            "insert into ingredients_name_alias values (42,'NUTS PINE NUTS DRIED');\n",
            "#######################################\n",
            "SPICIES\n",
            "SPICIES\n",
            "1.0\n",
            "SPICIES\n",
            "0.9999999403953552\n",
            "update ingredients set carbon_foot_print =0.84, water_foot_print = 8280, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =61;\n",
            "insert into ingredients_name_alias values (61,'SPICES PEPPER RED OR CAYENNE');\n",
            "#######################################\n",
            "NUTS\n",
            "NUTS\n",
            "1.0\n",
            "NUTS\n",
            "1.0\n",
            "update ingredients set carbon_foot_print =1.11, water_foot_print = 11264, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =79;\n",
            "insert into ingredients_name_alias values (79,'NUTS MACADAMIA NUTS RAW');\n",
            "#######################################\n",
            "VEGETABLES\n",
            "VEGETABLES\n",
            "0.9999999403953552\n",
            "VEGETABLES \n",
            "0.9999999403953552\n",
            "update ingredients set carbon_foot_print =0.33, water_foot_print = 336, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =116;\n",
            "insert into ingredients_name_alias values (116,'KALE RAW');\n",
            "#######################################\n",
            "VEGETABLES\n",
            "VEGETABLES\n",
            "0.9999999403953552\n",
            "VEGETABLES \n",
            "0.9999999403953552\n",
            "update ingredients set carbon_foot_print =0.33, water_foot_print = 336, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =124;\n",
            "insert into ingredients_name_alias values (124,'CHIVES RAW');\n",
            "#######################################\n",
            "SPICIES\n",
            "SPICIES\n",
            "1.0\n",
            "SPICIES\n",
            "0.9999999403953552\n",
            "update ingredients set carbon_foot_print =0.84, water_foot_print = 8280, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =144;\n",
            "insert into ingredients_name_alias values (144,'DILL WEED FRESH');\n",
            "#######################################\n",
            "SPICIES\n",
            "SPICIES\n",
            "1.0\n",
            "SPICIES\n",
            "0.9999999403953552\n",
            "update ingredients set carbon_foot_print =0.84, water_foot_print = 8280, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =148;\n",
            "insert into ingredients_name_alias values (148,'PARSLEY FRESH');\n",
            "#######################################\n",
            "SPICIES\n",
            "SPICIES\n",
            "1.0\n",
            "SPICIES\n",
            "0.9999999403953552\n",
            "update ingredients set carbon_foot_print =0.84, water_foot_print = 8280, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =174;\n",
            "insert into ingredients_name_alias values (174,'SPICES PEPPER BLACK');\n",
            "#######################################\n",
            "SPICIES\n",
            "SPICIES\n",
            "1.0\n",
            "SPICIES\n",
            "0.9999999403953552\n",
            "update ingredients set carbon_foot_print =0.84, water_foot_print = 8280, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =223;\n",
            "insert into ingredients_name_alias values (223,'SPICES BASIL DRIED');\n",
            "#######################################\n",
            "VEGETABLES\n",
            "VEGETABLES\n",
            "0.9999999403953552\n",
            "VEGETABLES \n",
            "0.9999999403953552\n",
            "update ingredients set carbon_foot_print =0.33, water_foot_print = 336, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =251;\n",
            "insert into ingredients_name_alias values (251,'SQUASH WINTER BUTTERNUT RAW');\n",
            "#######################################\n",
            "SPICIES\n",
            "SPICIES\n",
            "1.0\n",
            "SPICIES\n",
            "0.9999999403953552\n",
            "update ingredients set carbon_foot_print =0.84, water_foot_print = 8280, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =261;\n",
            "insert into ingredients_name_alias values (261,'TERRA DOLCE ORGANIC CHIPOTLE DRIED CHILE PEPPERS UPC: 700360007144');\n",
            "#######################################\n",
            "NUTS\n",
            "NUTS\n",
            "1.0\n",
            "NUTS\n",
            "1.0\n",
            "update ingredients set carbon_foot_print =1.11, water_foot_print = 11264, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =274;\n",
            "insert into ingredients_name_alias values (274,'NUTS PECANS');\n",
            "#######################################\n",
            "VEGETABLES\n",
            "VEGETABLES\n",
            "0.9999999403953552\n",
            "VEGETABLES \n",
            "0.9999999403953552\n",
            "update ingredients set carbon_foot_print =0.33, water_foot_print = 336, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =284;\n",
            "insert into ingredients_name_alias values (284,'ARUGULA RAW');\n",
            "#######################################\n",
            "POULTRY BONE FREE MEAT\n",
            "POULTRY BONE FREE MEAT\n",
            "0.9999998807907104\n",
            "POULTRY BONE FREE MEAT\n",
            "0.9999998807907104\n",
            "update ingredients set carbon_foot_print =3.88, water_foot_print = 4325, carbon_foot_print_source\t= 'sueatable_typology_median_values', carbon_foot_print_weight=1000, water_foot_print_source= 'sueatable_typology_median_values', water_foot_print_weight =\t1000 where ingredient_id =295;\n",
            "insert into ingredients_name_alias values (295,'KASHI STEAM MEAL CHICKEN FETTUCCINE FROZEN ENTREE');\n",
            "#######################################\n"
          ]
        }
      ]
    }
  ]
}